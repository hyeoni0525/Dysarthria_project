# ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ëª¨ë¸ ì¶”ë¡  ë° í‰ê°€ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥í•˜ë©° BLEURTì™€ Rougeë¥¼ í™œìš©í•¨

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast
import pandas as pd
import torch
from tqdm import tqdm
import evaluate
import re

# ë©”íŠ¸ë¦­ ë¡œë“œ
rouge = evaluate.load("rouge")
bleurt = evaluate.load("bleurt", module_type="metric")

# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
model_path = "/home/elicer/Project/kobart_correction_model/best"
tokenizer = PreTrainedTokenizerFast.from_pretrained(model_path)
model = BartForConditionalGeneration.from_pretrained(model_path)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv("/home/elicer/Project/CSV/inference_data.csv")

# ğŸ”§ í‰ê·  target ê¸¸ì´ ê³„ì‚°
target_length = int(df["target"].apply(lambda x: len(tokenizer.encode(str(x)))).mean())
print(f"ğŸ“ í‰ê·  target ê¸¸ì´: {target_length}")

# ì •ê·œí™” í•¨ìˆ˜
def normalize_text(text):
    return re.sub(r'\s+', ' ', str(text)).strip() if isinstance(text, str) else ""

# ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
predictions, references, sources = [], [], []
rouge1_scores, rouge2_scores, rougeL_scores, bleurt_scores = [], [], [], []

# ì¶”ë¡  ë° í‰ê°€ ì‹œì‘
for idx, row in tqdm(df.iterrows(), total=len(df)):
    try:
        source_text, target_text = str(row["source"]), str(row["target"])
        inputs = tokenizer(source_text, return_tensors="pt", max_length=512, padding="max_length", truncation=True)
        inputs.pop("token_type_ids", None)
        inputs = {k: v.to(device) for k, v in inputs.items()}

        with torch.no_grad():
            output = model.generate(**inputs, max_new_tokens=target_length+10, num_beams=5, early_stopping=True, no_repeat_ngram_size=3)

        decoded_output = normalize_text(tokenizer.decode(output[0], skip_special_tokens=True))
        target_text = normalize_text(target_text)

        predictions.append(decoded_output)
        references.append(target_text)
        sources.append(source_text)

        # ROUGE
        try:
            result = rouge.compute(predictions=[decoded_output], references=[target_text], tokenizer=lambda x: x.split(), use_stemmer=False)
            rouge1_scores.append(result.get("rouge1", 0.0))
            rouge2_scores.append(result.get("rouge2", 0.0))
            rougeL_scores.append(result.get("rougeL", 0.0))
        except:
            rouge1_scores.append(0.0)
            rouge2_scores.append(0.0)
            rougeL_scores.append(0.0)

        # BLEURT
        try:
            bleurt_score = bleurt.compute(predictions=[decoded_output], references=[target_text])["scores"][0]
        except:
            bleurt_score = 0.0
        bleurt_scores.append(bleurt_score)

    except Exception as e:
        print(f"ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        predictions.append("")
        references.append(row.get("target", ""))
        sources.append(row.get("source", ""))
        rouge1_scores.append(0.0)
        rouge2_scores.append(0.0)
        rougeL_scores.append(0.0)
        bleurt_scores.append(0.0)

# ê²°ê³¼ ì €ì¥
result_df = pd.DataFrame({
    "source": sources,
    "target": references,
    "predicted": predictions,
    "rouge1": rouge1_scores,
    "rouge2": rouge2_scores,
    "rougeL": rougeL_scores,
    "bleurt": bleurt_scores
})

result_df.to_csv("/home/elicer/Project/results/inference_results.csv", index=False)
print("\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: inference_results.csv")

# í‰ê·  ì„±ëŠ¥ ì¶œë ¥
def avg(lst): return round(sum(lst)/len(lst), 4) if lst else 0
print("\n===== í‰ê·  ì„±ëŠ¥ =====")
print(f"ROUGE-1: {avg(rouge1_scores)}")
print(f"ROUGE-2: {avg(rouge2_scores)}")
print(f"ROUGE-L: {avg(rougeL_scores)}")
print(f"BLEURT: {avg(bleurt_scores)}")
